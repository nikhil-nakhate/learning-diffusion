{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f8bf7f",
   "metadata": {},
   "source": [
    "# Basics of diffusion models\n",
    "In the last few years diffusion models demonstrated to be a fundamental paradigm for generative modelling across a number of domains ranging from generating images, videos, proteins and much more. In this series of notebooks we're gonna take a look at them with a practical approach, implementing every step needed. Starting from the basics, we will see a first toy example, moving them to image generation and advanced approaches such as classifier-free guidance, flow matching and latent diffusion.\n",
    "But first, let's start from the basics.\n",
    "Reference paper: [_Denoising Diffusion Probabilistic Models_](https://arxiv.org/abs/2006.11239)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980dd9e1",
   "metadata": {},
   "source": [
    "## What are diffusion models?\n",
    "At a high level, diffusion models consist of two main processes:\n",
    "\n",
    "- Forward Diffusion (The Destruction): We gradually add Gaussian noise to our data until it becomes unrecognizable random static. This is a fixed mathematical process (no neural network training yet).\n",
    "\n",
    "- Reverse Diffusion (The Creation): We train a neural network to look at a slightly noisy image and predict the noise that was added. By subtracting this predicted noise step-by-step, we can go from pure static back to structured data.\n",
    "\n",
    "So in the end, the generation process consists of our network learning to denoise a completely noisey starting sample towards a sample that resembles the distribution of data the model was trained on.\n",
    "In this notebook we are going to see one of the basic formulation of diffusion models: DDPM (Denoising Diffusion Probabilistic Models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d5f46",
   "metadata": {},
   "source": [
    "### Step 1: The Data\n",
    "Before we destroy data, we need data to destroy! For a toy example, 2D points (x, y coordinates) are easier to visualize than images. A \"Swiss Roll\" or a \"Spiral\" is a classic choice because it's hard for simple models to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc395fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, title=None):\n",
    "    # plot initial data\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=10, alpha=0.6, c='purple')\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def get_spiral_data(n_points=1000):\n",
    "    theta = np.sqrt(np.random.rand(n_points)) * 720 * (np.pi / 180)\n",
    "    r = 0.5 * theta \n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    data = np.stack([x, y], axis=1) + np.random.randn(n_points, 2) * 0.3\n",
    "    data_max = np.max(np.abs(data))\n",
    "    data = data / data_max\n",
    "    return data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0074bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_spiral_data()\n",
    "plot_data(data, title=\"Target Distribution: 2D Spiral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956cd3c",
   "metadata": {},
   "source": [
    "### Step 2: The Forward Diffusion Process\n",
    "Our goal is to take this nice spiral (let's call it $x_0$) and slowly corrupt it over $T$ time steps until it looks like pure Gaussian noise ($x_T$). This step is called Forward Diffusion Process:\n",
    "For each noising step, we add some amount of gaussian noise to the previous sample $x_{t-1}$ int the following way:\n",
    "$$x_t = \\sqrt{1 - \\beta_t} \\cdot x_{t-1} + \\sqrt{\\beta_t} \\cdot \\epsilon$$\n",
    "Where:\n",
    "- $\\epsilon$: The Gaussian noise you mentioned.\n",
    "- $\\beta_t$ (beta): A small number between 0 and 1 that controls how much noise to add at this specific step.\n",
    "Notice that our beta values have a dependence over time, as we define a scheduling over the steps where we slowly increase the values (a typical range is 1e-4 to 0.02).\n",
    "<br>\n",
    "The function below implements this forward diffusion process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion_step(x, t, betas):\n",
    "    # sample gaussian noise\n",
    "    noise = torch.randn_like(x)\n",
    "    # get beta for current timestep\n",
    "    b_t = betas[t]\n",
    "    # add noise to x (forward diffusion)\n",
    "    x_t = torch.sqrt(1-b_t) * x + torch.sqrt(b_t) * noise\n",
    "    \n",
    "    return x_t\n",
    "    \n",
    "def forward_diffusion(x, diffusion_steps, betas):\n",
    "    x_values = [x]\n",
    "    for i in range(diffusion_steps):\n",
    "        x_t = forward_diffusion_step(x, i, betas)\n",
    "        x_values.append(x_t)\n",
    "        x = x_t\n",
    "    return x, x_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1b916",
   "metadata": {},
   "source": [
    "Let's now take a look at what's happening over time to our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e201c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_steps = 6\n",
    "# schedule beta values\n",
    "betas = torch.linspace(0.0001, 0.02, diffusion_steps)\n",
    "\n",
    "x_0 = torch.tensor(data).float()\n",
    "x_noisy, x_values = forward_diffusion(x_0, diffusion_steps, betas)\n",
    "\n",
    "# plot progressive noising\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12,8))\n",
    "for i in range(diffusion_steps):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.scatter(x_values[i][:, 0].numpy(), x_values[i][:, 1].numpy(), s=10, alpha=0.6, c='purple')\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.set_title(f\"Step {i}\")\n",
    "    ax.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca368569",
   "metadata": {},
   "source": [
    "Actually, there's a much faster method to get a noisy sample at time $t$. Right now, we are required to loop through every forward diffusion step starting from the clean image. Turns out there is a mathematical shortcut to directly \"teleport\" to a certain noisy sample $x_t$ using just $x_0$. To do this, we usually define two helper variables:\n",
    "- $\\alpha_t = 1 - \\beta_t$ (this represents how much \"signal\" we keep at each step).\n",
    "- $\\bar{\\alpha}_t$ (read \"alpha bar\"): the cumulative product of all alphas up to time $t$.\n",
    "The shortcut formula looks like this:\n",
    "$$x_t = \\sqrt{\\bar{\\alpha}_t} \\cdot x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\cdot \\epsilon$$\n",
    "Let's look at an implementation of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_t(x_0, t, alpha_bars):\n",
    "    # sample noise\n",
    "    epsilon = torch.randn_like(x_0)\n",
    "    # get x_t using closed form equation\n",
    "    x_t = torch.sqrt(alpha_bars[t]) * x_0 + torch.sqrt(1-alpha_bars[t]) * epsilon\n",
    "    \n",
    "    return x_t, epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dead4af",
   "metadata": {},
   "source": [
    "And here's the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23775fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try playing with different time steps t\n",
    "n_steps = 200\n",
    "betas = torch.linspace(1e-4, 0.02, n_steps)\n",
    "alphas = 1-betas\n",
    "alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "t = 40\n",
    "x_t, epsilon = sample_t(x_0, t, alpha_bars)\n",
    "\n",
    "plot_data(x_t.numpy() - epsilon.numpy(), title=f\"Forward Diffusion Trick at Step {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e46eff",
   "metadata": {},
   "source": [
    "### Step 3: The Backward Process\n",
    "Now comes the interesting part: the reverse diffusion process. This is where our neural network comes into play. The goal is to learn how to \"undo\" the forward diffusion process, going from noisy data $x_t$ back to cleaner data $x_{t-1}$.\n",
    "\n",
    "The key insight is that we train our network to predict the noise $\\epsilon$ that was added during the forward process. Once we have this predicted noise, we can use it to reconstruct a cleaner version of the data. The reverse step formula looks like this:\n",
    "\n",
    "$$x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\cdot \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t \\cdot z$$\n",
    "\n",
    "Where:\n",
    "- $\\epsilon_\\theta(x_t, t)$: The noise predicted by our neural network (parameterized by $\\theta$).\n",
    "- $\\alpha_t = 1 - \\beta_t$: How much signal we kept at step $t$.\n",
    "- $\\bar{\\alpha}_t$: The cumulative product of alphas up to time $t$.\n",
    "- $\\sigma_t$: The standard deviation of the noise we add back (for stochasticity).\n",
    "- $z$: A random Gaussian noise sample (set to zero at the final step $t=0$).\n",
    "\n",
    "The intuition here is that we're essentially \"subtracting\" the predicted noise from the noisy sample, then scaling and adding a small amount of randomness to get the previous timestep. By repeating this process from $x_T$ (pure noise) all the way down to $x_0$ (clean data), we can generate new samples that follow our training distribution.\n",
    "\n",
    "The functions below implement this reverse diffusion process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, x_t, alpha_t, alpha_bar_t, sigma_t, t):\n",
    "    epsilon = model(x_t, t) # The model input is x_t and t and the output is the predicted noise\n",
    "    if t.numel() > 1:\n",
    "        is_zero_timestep = (t[0] == 0)\n",
    "    else:\n",
    "        is_zero_timestep = (t.item() == 0)\n",
    "        \n",
    "    if is_zero_timestep:\n",
    "        z = torch.zeros_like(x_t)\n",
    "    else:\n",
    "        z = torch.randn_like(x_t)\n",
    "    x_prev = 1/torch.sqrt(alpha_t) * (x_t - (1-alpha_t)/torch.sqrt(1-alpha_bar_t) * epsilon) + sigma_t * z\n",
    "    \n",
    "    return x_prev\n",
    "\n",
    "@torch.no_grad()\n",
    "def reverse_diffusion(model, x_t, timesteps, device):  \n",
    "    betas = torch.linspace(1e-4, 0.02, timesteps, device=device)\n",
    "    alphas = 1-betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    \n",
    "    batch_size = x_t.shape[0]  # Get the batch size\n",
    "    \n",
    "    model.eval()\n",
    "    for t in range(timesteps-1, -1, -1):\n",
    "        alpha_t = alphas[t]\n",
    "        alpha_bar_t = alpha_bars[t]\n",
    "        sigma_t = torch.sqrt(betas[t]) # The standard deviation of the noise is the square root of the betas\n",
    "        # Expand t to match batch size\n",
    "        t_batch = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "        x_prev = sample(model, x_t, alpha_t, alpha_bar_t, sigma_t, t_batch)\n",
    "        x_t = x_prev\n",
    "    return x_t\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5f66f",
   "metadata": {},
   "source": [
    "### Spiral generation\n",
    "Now that we understand both the forward and backward processes, let's put it all together! We need to:\n",
    "\n",
    "1. **Build a neural network** that can predict noise given a noisy sample and a timestep. This network needs to understand both the structure of the data (the spiral shape) and how much noise is present at different timesteps.\n",
    "\n",
    "2. **Train the network** by showing it many examples of noisy spirals at different noise levels, and asking it to predict the noise that was added.\n",
    "\n",
    "3. **Generate new spirals** by starting with pure noise and iteratively denoising it using our trained network.\n",
    "\n",
    "The network architecture we'll use includes:\n",
    "- **Time embeddings**: Since the amount of noise varies by timestep, we need to tell the network which timestep we're at. We use sinusoidal embeddings (similar to positional encodings in transformers) to encode the timestep.\n",
    "- **Residual connections**: These help the network learn more effectively by allowing gradients to flow through multiple paths.\n",
    "- **Layer normalization**: This stabilizes training and helps the network converge faster.\n",
    "\n",
    "Let's start by defining the network components:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4807796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "    def forward(self, t):\n",
    "            device = t.device\n",
    "            emb = torch.zeros(t.shape[0], self.embedding_dim, device=device)\n",
    "            \n",
    "            for i in range(self.embedding_dim // 2):\n",
    "                # We ensure the constant is on the correct device too\n",
    "                const = torch.tensor(10000.0, device=device) \n",
    "                omega_i = torch.exp(-(2*i/self.embedding_dim) * torch.log(const))\n",
    "                \n",
    "                emb[:, 2*i] = torch.sin(omega_i * t)\n",
    "                emb[:, 2*i+1] = torch.cos(omega_i * t)\n",
    "            \n",
    "            return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a64749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiserNetwork(nn.Module):\n",
    "    def __init__(self, sample_dim=2, time_embedding_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.time_embedder = SinusoidalEmbedding(time_embedding_dim)\n",
    "        \n",
    "        # Project time embedding to hidden dim\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_embedding_dim, hidden_dim),\n",
    "            nn.SiLU(),  # SiLU (Swish) often works better than ReLU for diffusion\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(sample_dim, hidden_dim)\n",
    "        \n",
    "        # Main network with residual connections and normalization\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, sample_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        # x: (batch_size, 2) noisy samples\n",
    "        # t: (batch_size,) timesteps\n",
    "        \n",
    "        # Embed time\n",
    "        t_emb = self.time_embedder(t)  # (batch, time_embedding_dim)\n",
    "        t_emb = self.time_mlp(t_emb)   # (batch, hidden_dim)\n",
    "        \n",
    "        # Project input\n",
    "        h = self.input_proj(x)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Add time embedding (additive conditioning)\n",
    "        h = h + t_emb\n",
    "        \n",
    "        # Residual blocks\n",
    "        for block in self.blocks:\n",
    "            h = h + block(h)  # Residual connection\n",
    "        \n",
    "        # Output\n",
    "        return self.output_proj(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb0bbe",
   "metadata": {},
   "source": [
    "We make our spiral dataset such that within each batch we have a number of random noised samples, picked with the trick for forward diffusion we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiralDataset(Dataset):\n",
    "    def __init__(self, n_points=1000, timesteps = 200):\n",
    "        self.data = get_spiral_data(n_points)\n",
    "        # plot initial data\n",
    "        plot_data(self.data, title=\"Training Data: 2D Spiral\")\n",
    "        self.timesteps = timesteps\n",
    "        self.alpha_bars = torch.cumprod(1-torch.linspace(1e-4, 0.02, timesteps), dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # sample a random timestep\n",
    "        t = torch.randint(0, self.timesteps, (1,)).item()\n",
    "        # get the data point\n",
    "        x_0 = torch.tensor(self.data[index]).float()\n",
    "        # get x_t and epsilon using the forward diffusion trick\n",
    "        x_t, epsilon = sample_t(x_0, torch.tensor(t), self.alpha_bars)\n",
    "        \n",
    "        return x_t, t, epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e81ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 300\n",
    "n_points = 2000\n",
    "\n",
    "# 1. Device Setup for M1\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Instantiate Dataset & DataLoader\n",
    "dataset = SpiralDataset(n_points=n_points, timesteps=timesteps) # Make sure the fix is in here!\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# 3. Instantiate Model\n",
    "model = DenoiserNetwork(sample_dim=2, time_embedding_dim=32, hidden_dim=256)\n",
    "model.to(device)\n",
    "\n",
    "# 4. Optimizer & Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    for x_t, t, epsilon in dataloader:\n",
    "        x_t = x_t.to(device)\n",
    "        t = t.to(device)\n",
    "        epsilon = epsilon.to(device)\n",
    "        \n",
    "        pred_epsilon = model(x_t, t)\n",
    "        loss = loss_fn(pred_epsilon, epsilon)\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1} loss: {avg_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate pure noise\n",
    "x_T = torch.randn(n_points, 2).to(device)\n",
    "\n",
    "# 2. Run the reverse process\n",
    "# This might take a few seconds as it loops 300 times\n",
    "generated_data = reverse_diffusion(model, x_T, timesteps, device=device)\n",
    "\n",
    "# 3. Plot the result\n",
    "generated_data = generated_data.cpu().numpy()\n",
    "\n",
    "plot_data(generated_data, title=\"Generated Data after Reverse Diffusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc17b3",
   "metadata": {},
   "source": [
    "### Conditional generation\n",
    "So far, we've seen how to generate samples from a single distribution (the spiral). But what if we want to control what we generate? This is where conditional generation comes in.\n",
    "\n",
    "The idea is simple: we add an additional input to our network that tells it what kind of sample we want to generate. In our case, we'll train on two different shapes: spirals and circles. The network will learn to generate spirals when given one label, and circles when given another.\n",
    "\n",
    "To make this work, we need to:\n",
    "1. **Modify the dataset** to include labels (0 for spiral, 1 for circle).\n",
    "2. **Modify the network** to accept and process these labels. We'll use an embedding layer to convert the discrete label into a continuous vector that can be added to the network's hidden representations.\n",
    "3. **Modify the sampling process** to pass the desired label during generation.\n",
    "\n",
    "This same principle extends to more complex scenarios: you could condition on text descriptions (like \"a red car\"), class labels (like \"cat\" or \"dog\"), or any other metadata you have. The network learns to associate these conditions with different modes of the data distribution.\n",
    "\n",
    "Let's start by creating a dataset with both shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circle_data(n_points=1000):\n",
    "    theta = np.random.rand(n_points) * 2 * np.pi\n",
    "    r = 0.8 # Fixed radius\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    \n",
    "    # Stack and add noise\n",
    "    data = np.stack([x, y], axis=1) + np.random.randn(n_points, 2) * 0.06\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_data = get_circle_data()\n",
    "plot_data(circle_data, title=\"Target Distribution: 2D Circle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6078c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualShapeDataset(Dataset):\n",
    "    def __init__(self, n_points=1000, timesteps = 200):\n",
    "        self.spiral_data = torch.tensor(get_spiral_data(n_points)).float()\n",
    "        self.circle_data = torch.tensor(get_circle_data(n_points)).float()\n",
    "\n",
    "        self.data = torch.cat([self.spiral_data, self.circle_data], dim=0)\n",
    "        self.labels = torch.cat([torch.zeros(n_points).long(), torch.ones(n_points).long()])\n",
    "        \n",
    "        self.timesteps = timesteps\n",
    "        self.alpha_bars = torch.cumprod(1-torch.linspace(1e-4, 0.02, timesteps), dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        t = torch.randint(0, self.timesteps, (1,)).item()\n",
    "        x_0 = torch.tensor(self.data[index]).float()\n",
    "        x_t, epsilon = sample_t(x_0, torch.tensor(t), self.alpha_bars)\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return x_t, t, epsilon, label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c417bd1",
   "metadata": {},
   "source": [
    "Our conditional version of the diffusion model shares all core components with the unconditional one, but implements a new linear layer that embeds the label (0 or 1 in this case) and after projection adds it to the time embedding to condition the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDenoiserNetwork(nn.Module):\n",
    "    def __init__(self, sample_dim=2, time_embedding_dim=64, hidden_dim=256, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.time_embedder = SinusoidalEmbedding(time_embedding_dim)\n",
    "        \n",
    "        # Project time embedding to hidden dim\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_embedding_dim, hidden_dim),\n",
    "            nn.SiLU(),  # SiLU (Swish) often works better than ReLU for diffusion\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(sample_dim, hidden_dim)\n",
    "        \n",
    "        # Label embedding\n",
    "        self.label_embedder = nn.Embedding(num_classes, hidden_dim)\n",
    "        \n",
    "        # Main network with residual connections and normalization\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, sample_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t, label):\n",
    "        # x: (batch_size, 2) noisy samples\n",
    "        # t: (batch_size,) timesteps\n",
    "        \n",
    "        # Embed time\n",
    "        t_emb = self.time_embedder(t)  # (batch, time_embedding_dim)\n",
    "        t_emb = self.time_mlp(t_emb)   # (batch, hidden_dim)\n",
    "        \n",
    "        # Project input\n",
    "        h = self.input_proj(x)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Add time embedding (additive conditioning)\n",
    "        h = h + t_emb\n",
    "        \n",
    "        # Add label embedding (additive conditioning)\n",
    "        label_emb = self.label_embedder(label)\n",
    "        h = h + label_emb\n",
    "        \n",
    "        # Residual blocks\n",
    "        for block in self.blocks:\n",
    "            h = h + block(h)  # Residual connection\n",
    "        \n",
    "        # Output\n",
    "        return self.output_proj(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69884c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 300\n",
    "n_samples = 2000\n",
    "# 1. Device Setup for M1\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Instantiate Dataset & DataLoader\n",
    "dataset = DualShapeDataset(n_points=2000, timesteps=timesteps) # Make sure the fix is in here!\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# 3. Instantiate Model\n",
    "model = ConditionalDenoiserNetwork(sample_dim=2, time_embedding_dim=32, hidden_dim=256, num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "# 4. Optimizer & Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca51317",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    for x_t, t, epsilon, labels in dataloader:\n",
    "        x_t = x_t.to(device)\n",
    "        t = t.to(device)\n",
    "        epsilon = epsilon.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred_epsilon = model(x_t, t, labels)\n",
    "        loss = loss_fn(pred_epsilon, epsilon)\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\"Epoch {epoch+1} loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9812cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_conditional(model, label,x_t, alpha_t, alpha_bar_t, sigma_t, t):\n",
    "    epsilon = model(x_t, t, label)\n",
    "    if t.numel() > 1:\n",
    "        is_zero_timestep = (t[0] == 0)\n",
    "    else:\n",
    "        is_zero_timestep = (t.item() == 0)\n",
    "        \n",
    "    if is_zero_timestep:\n",
    "        z = torch.zeros_like(x_t)\n",
    "    else:\n",
    "        z = torch.randn_like(x_t)\n",
    "    x_prev = 1/torch.sqrt(alpha_t) * (x_t - (1-alpha_t)/torch.sqrt(1-alpha_bar_t) * epsilon) + sigma_t * z\n",
    "    \n",
    "    return x_prev\n",
    "\n",
    "@torch.no_grad()\n",
    "def reverse_diffusion_conditional(model, x_t, label,timesteps, device):  \n",
    "    betas = torch.linspace(1e-4, 0.02, timesteps, device=device)\n",
    "    alphas = 1-betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    \n",
    "    batch_size = x_t.shape[0]  # Get the batch size\n",
    "    \n",
    "    model.eval()\n",
    "    for t in range(timesteps-1, -1, -1):\n",
    "        alpha_t = alphas[t]\n",
    "        alpha_bar_t = alpha_bars[t]\n",
    "        sigma_t = torch.sqrt(betas[t])\n",
    "        # Expand t to match batch size\n",
    "        t_batch = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "        x_prev = sample_conditional(model, label, x_t, alpha_t, alpha_bar_t, sigma_t, t_batch)\n",
    "        x_t = x_prev\n",
    "    return x_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f652437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_conditional(model, label, timesteps):\n",
    "    # 1. Generate pure noise\n",
    "    label = torch.tensor([label]).to(device)\n",
    "    x_T = torch.randn(n_samples, 2).to(device)\n",
    "\n",
    "    # 2. Run the reverse process\n",
    "    # This might take a few seconds as it loops 300 times\n",
    "    generated_data = reverse_diffusion_conditional(model, x_T, label, timesteps, device=device)\n",
    "\n",
    "    # 3. Plot the result\n",
    "    generated_data = generated_data.cpu().numpy()\n",
    "    plot_data(generated_data, title=f\"Generated Data after Reverse Diffusion (Label={label.item()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f501b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot data conditioned on label\n",
    "label = 1  # 0: Spiral, 1: Circle\n",
    "predict_and_plot_conditional(model, label, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef9e47",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "Great! We've now implemented a complete diffusion model from scratch. Let's recap what we covered:\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Forward Diffusion**: A fixed process that gradually adds noise to data, transforming clean samples into pure Gaussian noise.\n",
    "- **Reverse Diffusion**: A learned process where a neural network predicts and removes noise, allowing us to generate new samples from pure noise.\n",
    "- **Conditional Generation**: Extending the model to generate specific types of samples by conditioning on labels or other metadata.\n",
    "\n",
    "**What Makes This Powerful:**\n",
    "The beauty of diffusion models lies in their simplicity and effectiveness. By breaking down generation into many small denoising steps, the model can learn complex data distributions without needing adversarial training (like GANs) or complex likelihood computations (like VAEs). Each step is relatively simple (just predict noise) but the cumulative effect is the ability to generate high-quality, diverse samples.\n",
    "\n",
    "**Next Steps:**\n",
    "This notebook covered the fundamentals, but there's so much more to explore:\n",
    "- **Classifier-Free Guidance**: A technique to improve conditional generation quality by training with both conditional and unconditional objectives.\n",
    "- **Flow Matching**: An alternative formulation that can be faster and more stable than traditional diffusion.\n",
    "- **Latent Diffusion**: Working in a compressed latent space (like Stable Diffusion) to generate high-resolution images efficiently.\n",
    "- **Gradient-Based Optimization**: Optimize the generation at test-time guided by a function that steers the generation towards a specific objective.\n",
    "\n",
    "The foundation we've built here will help you understand these more advanced techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
